{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5896b1a6-8ed4-4484-96e5-50d0ac10b73a",
   "metadata": {},
   "source": [
    "# [Supervised Fine-tuning Trainer](https://huggingface.co/docs/trl/sft_trainer)\n",
    "\n",
    "Supervised fine-tuning (or SFT for short) is a crucial step in RLHF. In TRL we provide an easy-to-use API to create your SFT models and train them with few lines of code on your dataset.\n",
    "\n",
    "[Python Script](https://github.com/huggingface/trl/blob/main/examples/scripts/sft.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f636b5-91b3-4a45-a6cf-334425eac4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install peft==0.7.1\n",
    "# !pip3 install trl==0.7.4\n",
    "# !pip3 install transformer==4.36.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd24274",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'4.36.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7263f867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\trl\\trainer\\ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.7.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import trl\n",
    "trl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74ed1948-2b9b-4324-ba26-36b6c95fdbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set GPU device\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "#os.environ['http_proxy']  = 'http://192.41.170.23:3128'\n",
    "#os.environ['https_proxy'] = 'http://192.41.170.23:3128'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14f87cd-e167-416a-912c-db3367cafd43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('json', data_files=\"C:\\\\Users\\\\Haneesha\\\\OneDrive\\\\Desktop\\\\NLP\\\\A8\\\\alpaca_data.json\", split=\"train\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628b8a29-e81f-40a8-8d00-ee2f2b8bec54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'The three primary colors are red, blue, and yellow.',\n",
       " 'instruction': 'What are the three primary colors?',\n",
       " 'input': ''}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\datasets\\load.py:1461: FutureWarning: The repository for tatsu-lab/alpaca_eval contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tatsu-lab/alpaca_eval\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output'],\n",
       "    num_rows: 805\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpaca_eval=load_dataset(\"tatsu-lab/alpaca_eval\",split='eval')\n",
    "alpaca_eval=alpaca_eval.remove_columns([\"dataset\",\"generator\"])\n",
    "alpaca_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5fe13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'How did US states get their names?',\n",
       " 'output': 'US states get their names from a variety of sources, including Native American tribes, Spanish explorers, British colonists, and even presidents. For example, the state of Alabama was named after the Native American tribe that lived in the area, while the state of Florida gets its name from the Spanish explorer, Ponce de Leon, who explored the area in the 1500s. Other states are named after English kings (like Virginia, named after England\\'s \"Virgin Queen,\" Queen Elizabeth I) or presidents (like Washington, named after George Washington).'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpaca_eval[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a32e505-24a5-4cd7-9f6b-25c1105ca996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load the model & Tokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name_or_path = \"distilgpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, \n",
    "    device_map = 'auto'\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path)\n",
    "\n",
    "# Make sure to pass a correct value for max_seq_length as the default value will be set to min(tokenizer.model_max_length, 1024).\n",
    "max_seq_length = min(tokenizer.model_max_length, 1024)\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2169a2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\n['Give three tips for staying healthy.', 'What are the three primary colors?']\\n\\n### Input:\\n['', '']\\n\\n### Response:\\n['1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\\\n2. Exercise regularly to keep your body active and strong. \\\\n3. Get enough sleep and maintain a consistent sleep schedule.', 'The three primary colors are red, blue, and yellow.']\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "    output_texts = []\n",
    "\n",
    "\n",
    "    if isinstance(examples, str):\n",
    "        examples = json.loads(examples)\n",
    "\n",
    "\n",
    "    if not isinstance(examples, list):\n",
    "        examples = [examples]\n",
    "\n",
    "    for i, example in enumerate(examples):\n",
    "        instruction = example.get(\"instruction\", \"\")\n",
    "        input_text = example.get(\"input\", \"\")\n",
    "        response = example.get(\"output\", \"\")\n",
    "\n",
    "        text = \"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "\"\"\".format(instruction)\n",
    "\n",
    "        if input_text:\n",
    "            text += \"### Input:\\n{}\\n\\n\".format(input_text)\n",
    "\n",
    "        text += \"### Response:\\n{}\".format(response)\n",
    "\n",
    "        output_texts.append(text.strip())\n",
    "\n",
    "    return output_texts\n",
    "\n",
    "# Check instruction-prompt\n",
    "formatting_prompts_func(dataset[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7eb9790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForCompletionOnlyLM(tokenizer=GPT2TokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}, mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "response_template = \" ### Answer:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4899f",
   "metadata": {},
   "source": [
    "**Model Training**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1610979a-eaa1-4773-9912-92c125c8dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the Trainer\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "save_path='./trainer/trainer_model'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = './trainer', #default = 'tmp_trainer'\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='epoch',\n",
    "    gradient_checkpointing=True,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    \n",
    "    num_train_epochs=5, #default = 3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8669b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a38bd1664e4df4816c73860e7891f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec08b7db6e744927b96feec3f69320f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/805 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d774a5ffb1144ce881210b0c38e1424f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\trl\\trainer\\utils.py:120: UserWarning: Could not find response key ` ### Answer:` in the following instance: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "['Give three tips for staying healthy.', 'What are the three primary colors?', 'Describe the structure of an atom.', 'How can we reduce air pollution?', 'Describe a time when you had to make a difficult decision.', 'Identify the odd one out.', 'Explain why the following fraction is equivalent to 1/4', 'Write a short story in third person narration about a protagonist who has to make an important career decision.', 'Render a 3D model of a house', 'Evaluate this sentence for spelling and grammar mistakes', 'How did Julius Caesar die?', 'What is the capital of France?', 'Generate a list of ten items a person might need for a camping trip', 'Discuss the causes of the Great Depression', 'Classify the following into animals, plants, and minerals', 'Explain the use of word embeddings in Natural Language Processing', 'Describe the function of a computer motherboard', 'Reverse engineer this code to create a new version', 'Propose an ethical solution to the problem of data privacy', 'Generate three verbs that mean the same as \"to apologize\"', 'What does DNA stand for?', 'Compare and contrast the Cuban Missile Crisis and the Vietnam War.', 'Generate a list of random words.', 'Transcribe the recording into text.', \"Who is the world's most famous painter?\", 'Explain the concept of cogging torque.', 'Look up the boiling point of water.', 'Describe the life and reign of King Charles II.', 'Find the area of a circle given its radius.', 'Identify the lines of longitude that divides North and South America.', 'Explain the process of cellular respiration in plants.', 'Rewrite the following sentence using active voice.', 'Generate a list of adjectives that describe a person as brave.', 'Outline the consequences of deforestation.', 'Develop a plan to reduce electricity usage in a home.', 'Arrange the words in the given sentence to form a grammatically correct sentence.', 'Analyze the given text for its tone.', 'Use the given data to calculate the median.', 'Rewrite the given paragraph in a shorter, easier to understand form.', 'Design a logo for a website about recycling.', 'Generate a poem that expresses joy.', 'Convert the given equation into an algebraic expression.', 'Brainstorm possible solutions to reduce water pollution.', 'Explain why the given definition is wrong.', 'Variable x is defined as “4x + 2y = 10”. Find the value of x.', 'Write a short paragraph about the given topic.', 'Explain the concept of artificial intelligence in simple terms.', 'Design an app for a delivery company.', 'Summarize the given passage.', 'Extract the facts from the paragraph.', 'Edit the following sentence to make it more concise.', 'Generate a poem with 10 lines.', 'Convert from celsius to fahrenheit.', 'Arrange the given numbers in ascending order.', 'Calculate the total surface area of a cube with a side length of 5 cm.', 'What is the force on a 1 kg mass due to the gravitational force?', 'Provide one example for a cultural practice.', 'Given a set of numbers, find the maximum value.', 'Give two examples of a liquid.', 'What is the product of 6 and 2?', 'What type of plant is a skunk cabbage?', 'Convert the given binary number to its decimal equivalent.', 'Name two types of desert biomes.', 'Given a sentence, convert it into passive voice.', 'Transform the following sentence into the passive voice', 'Create a dialog between two people who are discussing a scientific phenomenon', 'Identify the most suitable adverb for the following sentence', 'Find the main idea of the following passage', 'Analyze the tone of the following sentences', 'Construct an argument to defend the following statement', 'Convert the following sentence into the present continuous tense', 'Give an example of a metaphor that uses the following object', 'Describe the following person', 'Construct a mathematical problem with the following numbers', 'Aim to reduce the following sentence without changing its meaning', 'Identify the conjunctions in the following sentence', 'Rewrite the following sentence in the third person', 'Generate a list of business ideas for a food delivery service.', 'Edit the following sentence to improve clarity and flow.', 'Imagine you are speaking with a customer who is unsatisfied with the product they bought from you. Construct a response that diffuses the situation.', 'Explain the concept of a bubble sort algorithm to This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\trl\\trainer\\utils.py:120: UserWarning: Could not find response key ` ### Answer:` in the following instance: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "['What are the names of some famous actors that started their careers on Broadway?', 'How did US states get their names?', \"Hi, my sister and her girlfriends want me to play kickball with them. Can you explain how the game is played, so they don't take advantage of me?\", 'What is some cool music from the 1920s?', 'How do I wrap a present neatly?', 'How do I dice without slicing my finger', \"Hi, I'm trying to solve a crossword puzzle, but I've never done one of these before. Can you help me out?\", 'Who is Larry Page?', 'What are different drawers I should have for clothes?', 'I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting. I am interested in trying some Georgian  dishes. Can you give me a recipe for Kubdari?', 'do you think retinoid is effective on removing the acne? because I have a lot of it', \"I'm trying to teach myself to have nicer handwriting. Can you help?\", 'I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting. I am interested in trying some Somali  dishes. Can you give me a recipe for Canjeero?', 'What are the best exercises for beginners?', 'Do you know why turkeys became the official food of thanksgiving?', 'I want to get better at networking at work', 'Are there any weird Christmas traditions?', \"Hi, I'm interested in learning to play badminton. Can you explain the game to me?\", 'Do you know why cats always rub up against your legs?', 'I am going to try to roast a pig at home for Thanksgiving this year. What equipment and techniques do I need to successfully get a pig roasted?', 'Help me find a good rated electric saw.', 'What are some artists I might like if I like Billy Joel?', 'What type of soil is suitable for cactus?', 'How do you become an author?', 'What breed dog is smallest?', 'What are some species of bears that are now extinct?', 'What causes the northern lights?', 'What are some good foods to eat when you are sick? I am looking for something to make my girlfriend to eat.', 'Why is kobe beef so damn expensive?', 'How do I clean my armpits?', 'How do I detail a car?', 'I am going to make pumpkin pie for the first time.  Can you help me?', 'What kind of foods do they eat in Thailand', 'What are some good browser alternatives to Chrome?', 'Who created the Superman cartoon character?', 'What is Atlantis?', 'How do I make escargot?', 'What exactly causes volcanoes to form?', 'Hi, I have some falafel, but no tahini to put on them. Can you give me a recipe for making tahini?', \"Should I get my children a nanny? I'm so exhausted.\", 'When was Canada colonized?', 'How can I  use my phone less?', 'How did mankind discover that the earth was spherical, and why did they initially believe it to be flat?', 'What is Gremolata?', 'Why did humans evolve to believe in God?', 'what should i build a cabin out of?', 'Why do a lot of Scientists not believe in God or Satan?', 'I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting. I am interested in trying some Mauritian dishes. Can you give me a recipe for Mine Frite?', 'Why can I see the moon during the day?', 'How do I take care of a wooden table?', 'What year was the Yamato Battleship built?', 'Did they ever announce the release date for the new elder scrolls game?', 'I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting. I am interested in trying some Danish dishes. Can you give me a recipe for Flæskesteg?', 'Please tell me about the romantic relationship between Julius Caesar and Cleopatra.', \"Hi, I'm in the mood for a Bloody Mary. Can you give me a recipe for making one?\", 'What are some famous world music artists?', 'what are some good ways to spread ashes?', 'I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3483161bb444e68850836efb3eee6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./trainer\\checkpoint-1 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_runtime': 1.1213, 'eval_samples_per_second': 0.892, 'eval_steps_per_second': 0.892, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\trl\\trainer\\utils.py:120: UserWarning: Could not find response key ` ### Answer:` in the following instance: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "['Give three tips for staying healthy.', 'What are the three primary colors?', 'Describe the structure of an atom.', 'How can we reduce air pollution?', 'Describe a time when you had to make a difficult decision.', 'Identify the odd one out.', 'Explain why the following fraction is equivalent to 1/4', 'Write a short story in third person narration about a protagonist who has to make an important career decision.', 'Render a 3D model of a house', 'Evaluate this sentence for spelling and grammar mistakes', 'How did Julius Caesar die?', 'What is the capital of France?', 'Generate a list of ten items a person might need for a camping trip', 'Discuss the causes of the Great Depression', 'Classify the following into animals, plants, and minerals', 'Explain the use of word embeddings in Natural Language Processing', 'Describe the function of a computer motherboard', 'Reverse engineer this code to create a new version', 'Propose an ethical solution to the problem of data privacy', 'Generate three verbs that mean the same as \"to apologize\"', 'What does DNA stand for?', 'Compare and contrast the Cuban Missile Crisis and the Vietnam War.', 'Generate a list of random words.', 'Transcribe the recording into text.', \"Who is the world's most famous painter?\", 'Explain the concept of cogging torque.', 'Look up the boiling point of water.', 'Describe the life and reign of King Charles II.', 'Find the area of a circle given its radius.', 'Identify the lines of longitude that divides North and South America.', 'Explain the process of cellular respiration in plants.', 'Rewrite the following sentence using active voice.', 'Generate a list of adjectives that describe a person as brave.', 'Outline the consequences of deforestation.', 'Develop a plan to reduce electricity usage in a home.', 'Arrange the words in the given sentence to form a grammatically correct sentence.', 'Analyze the given text for its tone.', 'Use the given data to calculate the median.', 'Rewrite the given paragraph in a shorter, easier to understand form.', 'Design a logo for a website about recycling.', 'Generate a poem that expresses joy.', 'Convert the given equation into an algebraic expression.', 'Brainstorm possible solutions to reduce water pollution.', 'Explain why the given definition is wrong.', 'Variable x is defined as “4x + 2y = 10”. Find the value of x.', 'Write a short paragraph about the given topic.', 'Explain the concept of artificial intelligence in simple terms.', 'Design an app for a delivery company.', 'Summarize the given passage.', 'Extract the facts from the paragraph.', 'Edit the following sentence to make it more concise.', 'Generate a poem with 10 lines.', 'Convert from celsius to fahrenheit.', 'Arrange the given numbers in ascending order.', 'Calculate the total surface area of a cube with a side length of 5 cm.', 'What is the force on a 1 kg mass due to the gravitational force?', 'Provide one example for a cultural practice.', 'Given a set of numbers, find the maximum value.', 'Give two examples of a liquid.', 'What is the product of 6 and 2?', 'What type of plant is a skunk cabbage?', 'Convert the given binary number to its decimal equivalent.', 'Name two types of desert biomes.', 'Given a sentence, convert it into passive voice.', 'Transform the following sentence into the passive voice', 'Create a dialog between two people who are discussing a scientific phenomenon', 'Identify the most suitable adverb for the following sentence', 'Find the main idea of the following passage', 'Analyze the tone of the following sentences', 'Construct an argument to defend the following statement', 'Convert the following sentence into the present continuous tense', 'Give an example of a metaphor that uses the following object', 'Describe the following person', 'Construct a mathematical problem with the following numbers', 'Aim to reduce the following sentence without changing its meaning', 'Identify the conjunctions in the following sentence', 'Rewrite the following sentence in the third person', 'Generate a list of business ideas for a food delivery service.', 'Edit the following sentence to improve clarity and flow.', 'Imagine you are speaking with a customer who is unsatisfied with the product they bought from you. Construct a response that diffuses the situation.', 'Explain the concept of a bubble sort algorithm to This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Haneesha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\trl\\trainer\\utils.py:120: UserWarning: Could not find response key ` ### Answer:` in the following instance: Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "['What are the names of some famous actors that started their careers on Broadway?', 'How did US states get their names?', \"Hi, my sister and her girlfriends want me to play kickball with them. Can you explain how the game is played, so they don't take advantage of me?\", 'What is some cool music from the 1920s?', 'How do I wrap a present neatly?', 'How do I dice without slicing my finger', \"Hi, I'm trying to solve a crossword puzzle, but I've never done one of these before. Can you help me out?\", 'Who is Larry Page?', 'What are different drawers I should have for clothes?', 'I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting. I am interested in trying some Georgian  dishes. Can you give me a recipe for Kubdari?', 'do you think retinoid is effective on removing the acne? because I have a lot of it', \"I'm trying to teach myself to have nicer handwriting. Can you help?\", 'I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting. I am interested in trying some Somali  dishes. Can you give me a recipe for Canjeero?', 'What are the best exercises for beginners?', 'Do you know why turkeys became the official food of thanksgiving?', 'I want to get better at networking at work', 'Are there any weird Christmas traditions?', \"Hi, I'm interested in learning to play badminton. Can you explain the game to me?\", 'Do you know why cats always rub up against your legs?', 'I am going to try to roast a pig at home for Thanksgiving this year. What equipment and techniques do I need to successfully get a pig roasted?', 'Help me find a good rated electric saw.', 'What are some artists I might like if I like Billy Joel?', 'What type of soil is suitable for cactus?', 'How do you become an author?', 'What breed dog is smallest?', 'What are some species of bears that are now extinct?', 'What causes the northern lights?', 'What are some good foods to eat when you are sick? I am looking for something to make my girlfriend to eat.', 'Why is kobe beef so damn expensive?', 'How do I clean my armpits?', 'How do I detail a car?', 'I am going to make pumpkin pie for the first time.  Can you help me?', 'What kind of foods do they eat in Thailand', 'What are some good browser alternatives to Chrome?', 'Who created the Superman cartoon character?', 'What is Atlantis?', 'How do I make escargot?', 'What exactly causes volcanoes to form?', 'Hi, I have some falafel, but no tahini to put on them. Can you give me a recipe for making tahini?', \"Should I get my children a nanny? I'm so exhausted.\", 'When was Canada colonized?', 'How can I  use my phone less?', 'How did mankind discover that the earth was spherical, and why did they initially believe it to be flat?', 'What is Gremolata?', 'Why did humans evolve to believe in God?', 'what should i build a cabin out of?', 'Why do a lot of Scientists not believe in God or Satan?', 'I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting. I am interested in trying some Mauritian dishes. Can you give me a recipe for Mine Frite?', 'Why can I see the moon during the day?', 'How do I take care of a wooden table?', 'What year was the Yamato Battleship built?', 'Did they ever announce the release date for the new elder scrolls game?', 'I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting. I am interested in trying some Danish dishes. Can you give me a recipe for Flæskesteg?', 'Please tell me about the romantic relationship between Julius Caesar and Cleopatra.', \"Hi, I'm in the mood for a Bloody Mary. Can you give me a recipe for making one?\", 'What are some famous world music artists?', 'what are some good ways to spread ashes?', 'I like to host guests at my home from time to time, and I am gathering  recipes of different dishes and drinks to keep things interesting This instance will be ignored in loss calculation. Note, if this happens often, consider increasing the `max_seq_length`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d2dd84c6ecc49b7b195a7963cebb529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./trainer\\checkpoint-2 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': nan, 'eval_runtime': 1.3994, 'eval_samples_per_second': 0.715, 'eval_steps_per_second': 0.715, 'epoch': 2.0}\n",
      "{'train_runtime': 14.5434, 'train_samples_per_second': 0.138, 'train_steps_per_second': 0.138, 'train_loss': 0.0, 'epoch': 2.0}\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "# Check if the tokenizer has a padding token defined\n",
    "if tokenizer.pad_token_id is None:\n",
    "    # If not, define a padding token and set it\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./trainer',  \n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='epoch',\n",
    "    gradient_checkpointing=True,\n",
    "    per_device_train_batch_size=3,\n",
    "    per_device_eval_batch_size=3,\n",
    "    num_train_epochs=2,  \n",
    ")\n",
    "\n",
    "# Define the Trainer\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset.select(range(1000)),\n",
    "    eval_dataset=alpaca_eval,\n",
    "    formatting_func=formatting_prompts_func,\n",
    "    data_collator=collator,\n",
    "    max_seq_length=max_seq_length,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "trainer.save_model(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "321d770c-7d3c-497b-bf87-56510676bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer,TextGenerationPipeline\n",
    "save_path='./trainer/trainer_model'\n",
    "model = AutoModelForCausalLM.from_pretrained(save_path)\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(save_path)\n",
    "\n",
    "# Create the text generation pipeline\n",
    "text_generator = TextGenerationPipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=model.device,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    max_length=100,  \n",
    "    temperature=1.0  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f26e774-a2ff-475a-927a-a5cfe7f413ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_instruction(sample):\n",
    "    if 'input' in sample.keys():\n",
    "        return f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{sample['instruction']}\n",
    "\n",
    "### Input:\n",
    "{sample['input']}\n",
    "\n",
    "### Response:\n",
    "\"\"\".strip()\n",
    "    else:\n",
    "        return f\"\"\"\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{sample['instruction']}\n",
    "\n",
    "### Response:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "905e614d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'How did US states get their names?',\n",
       " 'output': 'US states get their names from a variety of sources, including Native American tribes, Spanish explorers, British colonists, and even presidents. For example, the state of Alabama was named after the Native American tribe that lived in the area, while the state of Florida gets its name from the Spanish explorer, Ponce de Leon, who explored the area in the 1500s. Other states are named after English kings (like Virginia, named after England\\'s \"Virgin Queen,\" Queen Elizabeth I) or presidents (like Washington, named after George Washington).'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpaca_eval[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b0e377-4257-497e-9a82-2562734e95f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", device_map = 'auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "464a4157-e6d1-4e3e-8c4a-d2d56c57887c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0b8b9847e14a5eb00702be522003fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66987aa7df18485895804b9dfffaf61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13caed41aaa1452eba472e565bda49f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654c9f3a268249bcb574aff36e3ba4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72c7587fdb8484194a00b129bb7ac98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943ab3ad64754ab7aa78b374e3c23202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89f3cbcc0cd4b98a1e136094af42be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "How did US states get their names?\n",
      "\n",
      "Gold Response:\n",
      "US states get their names from a variety of sources, including Native American tribes, Spanish explorers, British colonists, and even presidents. For example, the state of Alabama was named after the Native American tribe that lived in the area, while the state of Florida gets its name from the Spanish explorer, Ponce de Leon, who explored the area in the 1500s. Other states are named after English kings (like Virginia, named after England's \"Virgin Queen,\" Queen Elizabeth I) or presidents (like Washington, named after George Washington).\n",
      "\n",
      "Generated Response:\n",
      "How did US states get their names?\n",
      "\n",
      "Numerous states have passed statutes designed to protect private information — including information that has been passed on by state. As a rule, the \"public\" information has to only be provided to officials of the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from transformers import pipeline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def compare_responses(pipeline, sample):\n",
    "    print(f\"Instruction:\\n{sample['instruction']}\\n\")\n",
    "\n",
    "    input_text = sample.get('input', '')\n",
    "    if input_text:\n",
    "        print(f\"Input:\\n{input_text}\\n\")\n",
    "\n",
    "    print(f\"Gold Response:\\n{sample['output']}\\n\")\n",
    "\n",
    "    response = pipeline(sample['instruction'])[0]['generated_text'].split(\"### Response:\\n\")[-1]\n",
    "\n",
    "    print(f\"Generated Response:\\n{response}\\n\")\n",
    "\n",
    "# Create a text generation pipeline\n",
    "text_generator = pipeline(\"text-generation\")\n",
    "\n",
    "# Usage example:\n",
    "compare_responses(text_generator, alpaca_eval[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606282d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
